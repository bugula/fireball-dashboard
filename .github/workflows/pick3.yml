name: Grab Illinois Pick 3

on:
  schedule:
    - cron: "*/15 * * * *"   # every 15 minutes (idempotent script avoids dupes)
  workflow_dispatch: {}       # allow manual runs from the Actions tab

jobs:
  run:
    runs-on: ubuntu-latest

    # Make the secrets available to all steps in this job
    env:
      GCP_SERVICE_ACCOUNT: ${{ secrets.GCP_SERVICE_ACCOUNT }}
      FIREBALL_DATA_SHEET_ID: ${{ secrets.FIREBALL_DATA_SHEET_ID }}
      # Only needed if you actually use the base64 variant in your script
      GCP_SERVICE_ACCOUNT_B64: ${{ secrets.GCP_SERVICE_ACCOUNT_B64 }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Install Playwright Chromium + system deps
      - name: Install Playwright Chromium
        run: |
          python -m playwright install --with-deps chromium

      # Optional: confirm envs exist (prints booleans only)
      - name: Debug env presence
        run: |
          python - <<'PY'
          import os
          print("HAS GCP_SERVICE_ACCOUNT:", bool(os.environ.get("GCP_SERVICE_ACCOUNT")))
          print("HAS FIREBALL_DATA_SHEET_ID:", bool(os.environ.get("FIREBALL_DATA_SHEET_ID")))
          PY

      - name: Run scraper
        run: python scrape_and_update.py
        timeout-minutes: 15

      - name: Run scraper (scrape-only)
        env:
          DEBUG_SCRAPE_ONLY: "1"
          GCP_SERVICE_ACCOUNT: ${{ secrets.GCP_SERVICE_ACCOUNT }}
          GCP_SERVICE_ACCOUNT_B64: ${{ secrets.GCP_SERVICE_ACCOUNT_B64 }}
        run: |
          python scrape_and_update.py
        timeout-minutes: 10

      - name: Upload debug artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-debug
          path: artifacts/**
